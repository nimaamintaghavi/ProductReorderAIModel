{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: awswrangler in /opt/conda/lib/python3.7/site-packages (2.15.1)\n",
      "Requirement already satisfied: openpyxl<3.1.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (3.0.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.21.6)\n",
      "Requirement already satisfied: redshift-connector<2.1.0,>=2.0.889 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (2.0.906)\n",
      "Requirement already satisfied: progressbar2<5.0.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (4.0.0)\n",
      "Requirement already satisfied: gremlinpython<4.0.0,>=3.5.2 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (3.6.0)\n",
      "Requirement already satisfied: pyarrow<7.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (6.0.1)\n",
      "Requirement already satisfied: backoff<2.0.0,>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.11.1)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.17 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.23.23)\n",
      "Requirement already satisfied: pymysql<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.0.2)\n",
      "Requirement already satisfied: opensearch-py<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.1.0)\n",
      "Requirement already satisfied: pg8000<2.0.0,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.26.0)\n",
      "Requirement already satisfied: requests-aws4auth<2.0.0,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.1.2)\n",
      "Requirement already satisfied: jsonpath-ng<2.0.0,>=1.5.3 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.5.3)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.3.5)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.17 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.20.23)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (1.26.7)\n",
      "Requirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (3.8.1)\n",
      "Requirement already satisfied: aenum<4.0.0,>=1.4.5 in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (3.1.11)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (0.6.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.5.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.14.0)\n",
      "Requirement already satisfied: ply in /opt/conda/lib/python3.7/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (3.11)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (4.4.1)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.7/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /opt/conda/lib/python3.7/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2021.10.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0.0,>=1.2.0->awswrangler) (2022.1)\n",
      "Requirement already satisfied: scramp>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from pg8000<2.0.0,>=1.20.0->awswrangler) (1.4.1)\n",
      "Requirement already satisfied: python-utils>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from progressbar2<5.0.0,>=4.0.0->awswrangler) (3.1.0)\n",
      "Requirement already satisfied: requests<2.27.2,>=2.23.0 in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.8.2)\n",
      "Requirement already satisfied: lxml>=4.6.5 in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (20.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (19.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (0.13.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.2.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (1.9.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<2.27.2,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.8)\n",
      "Requirement already satisfied: asn1crypto>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from scramp>=1.4.1->pg8000<2.0.0,>=1.20.0->awswrangler) (1.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.4.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 281 ms, sys: 56.5 ms, total: 338 ms\n",
      "Wall time: 390 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import awswrangler as wr\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}\n",
    "\n",
    "bucket = 'ads508team7'\n",
    "prefix = 'jump_start'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[region],role, instance_count=1, instance_type='ml.m5.xlarge',output_path='s3://{}/{}/output'.format(bucket, prefix),sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,eta=0.2,gamma=4,min_child_weight=6,subsample=0.8,silent=0,objective='binary:logistic',num_round=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-19 05:48:28 Starting - Starting the training job...\n",
      "2022-04-19 05:48:58 Starting - Preparing the instances for trainingProfilerReport-1650347308: InProgress\n",
      ".........\n",
      "2022-04-19 05:50:18 Downloading - Downloading input data.........\n",
      "2022-04-19 05:51:59 Training - Training image download completed. Training in progress.\u001b[33mArguments: train\u001b[0m\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[36mArguments: train\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:51:51:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:51:51:INFO] Number of hosts: 5, master IP address: 10.2.105.73, host IP address: 10.2.118.156.\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:51:51:INFO] Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[35mArguments: train\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:51:51:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:51:51:INFO] Number of hosts: 5, master IP address: 10.2.105.73, host IP address: 10.2.76.44.\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:51:51:INFO] Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[35mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-76-44.ec2.internal.out\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:51:51:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:51:51:INFO] Number of hosts: 5, master IP address: 10.2.105.73, host IP address: 10.2.113.127.\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:51:51:INFO] Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[33mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-113-127.ec2.internal.out\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:51:51:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:51:51:INFO] Number of hosts: 5, master IP address: 10.2.105.73, host IP address: 10.2.105.73.\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:51:51:INFO] Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[36mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-118-156.ec2.internal.out\u001b[0m\n",
      "\u001b[32mArguments: train\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:51:51:INFO] Running distributed xgboost training.\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:51:51:INFO] Number of hosts: 5, master IP address: 10.2.105.73, host IP address: 10.2.121.66.\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:51:51:INFO] Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[32mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-121-66.ec2.internal.out\u001b[0m\n",
      "\u001b[34mstarting namenode, logging to /opt/amazon/hadoop/logs/hadoop--namenode-ip-10-2-105-73.ec2.internal.out\u001b[0m\n",
      "\u001b[35mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-76-44.ec2.internal.out\u001b[0m\n",
      "\u001b[32mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-121-66.ec2.internal.out\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:51:56:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:51:56:INFO] File size need to be processed in the node: 144.04 mb. Available memory size in the node: {mem_size_str} mb\u001b[0m\n",
      "\u001b[33mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-113-127.ec2.internal.out\u001b[0m\n",
      "\u001b[36mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-118-156.ec2.internal.out\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:51:56:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:51:56:INFO] File size need to be processed in the node: 144.04 mb. Available memory size in the node: {mem_size_str} mb\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:51:56:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:51:56:INFO] File size need to be processed in the node: 144.04 mb. Available memory size in the node: {mem_size_str} mb\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:51:56:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:51:56:INFO] File size need to be processed in the node: 144.04 mb. Available memory size in the node: {mem_size_str} mb\u001b[0m\n",
      "\u001b[34mstarting resourcemanager, logging to /opt/amazon/hadoop/logs/yarn--resourcemanager-ip-10-2-105-73.ec2.internal.out\u001b[0m\n",
      "\u001b[34mstarting datanode, logging to /opt/amazon/hadoop/logs/hadoop--datanode-ip-10-2-105-73.ec2.internal.out\u001b[0m\n",
      "\u001b[34mstarting nodemanager, logging to /opt/amazon/hadoop/logs/yarn--nodemanager-ip-10-2-105-73.ec2.internal.out\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] File size need to be processed in the node: 144.04 mb. Available memory size in the node: {mem_size_str} mb\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] HTTP server started....\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] Memory/core ratio is 7.69\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] Yarn setup: number of workers: 5, physical cores per worker: 2, physical memory per worker: 15.38g.\u001b[0m\n",
      "\u001b[34m[2022-04-19:05:52:03:INFO] Yarn job submitted successfully.\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:03,931 INFO start listen on 10.2.105.73:9091\u001b[0m\n",
      "\u001b[34m/xgboost/dmlc-core/tracker/dmlc_tracker/yarn.py:36: UserWarning: cannot find \"/xgboost/dmlc-core/tracker/dmlc_tracker/../yarn/dmlc-yarn.jar\", I will try to run build\n",
      "  warnings.warn(\"cannot find \\\"%s\\\", I will try to run build\" % YARN_JAR_PATH)\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:37: warning: Signal is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[34mimport sun.misc.Signal;\n",
      "               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:38: warning: SignalHandler is internal proprietary API and may be removed in a future release\u001b[0m\n",
      "\u001b[34mimport sun.misc.SignalHandler;\n",
      "               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "        ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:276: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal intSignal = new Signal(\"INT\");\n",
      "                               ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:277: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        Signal.handle(intSignal, handler);\n",
      "        ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:332: warning: SignalHandler is internal proprietary API and may be removed in a future release\n",
      "    class CtrlCHandler implements SignalHandler{\n",
      "                                  ^\u001b[0m\n",
      "\u001b[34msrc/main/java/org/apache/hadoop/yarn/dmlc/Client.java:339: warning: Signal is internal proprietary API and may be removed in a future release\n",
      "        public void handle(Signal signal){\n",
      "                           ^\u001b[0m\n",
      "\u001b[34mNote: src/main/java/org/apache/hadoop/yarn/dmlc/ApplicationMaster.java uses unchecked or unsafe operations.\u001b[0m\n",
      "\u001b[34mNote: Recompile with -Xlint:unchecked for details.\u001b[0m\n",
      "\u001b[34m7 warnings\u001b[0m\n",
      "\u001b[34m22/04/19 05:52:09 INFO client.RMProxy: Connecting to ResourceManager at algo-1/10.2.105.73:8032\u001b[0m\n",
      "\u001b[34m22/04/19 05:52:09 INFO dmlc.Client: HDFS temp directory do not exist, creating.. /tmp\u001b[0m\n",
      "\u001b[34m22/04/19 05:52:11 INFO dmlc.Client: jobname=DMLC[nworker=5]:python3,username=root\u001b[0m\n",
      "\u001b[34m22/04/19 05:52:11 INFO dmlc.Client: Submitting application application_1650347519031_0001\u001b[0m\n",
      "\u001b[34m22/04/19 05:52:11 INFO impl.YarnClientImpl: Submitted application application_1650347519031_0001\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:18,114 INFO @tracker All of 5 nodes getting started\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:27,414 INFO [0]#011train-error:0.407093\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:30,274 INFO [1]#011train-error:0.407093\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:33,275 INFO [2]#011train-error:0.407093\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:36,224 INFO [3]#011train-error:0.406734\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:39,107 INFO [4]#011train-error:0.406462\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:42,026 INFO [5]#011train-error:0.406449\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:45,022 INFO [6]#011train-error:0.406246\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:47,903 INFO [7]#011train-error:0.40641\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:50,890 INFO [8]#011train-error:0.406363\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:53,883 INFO [9]#011train-error:0.406325\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:56,873 INFO [10]#011train-error:0.406281\u001b[0m\n",
      "\u001b[34m2022-04-19 05:52:59,869 INFO [11]#011train-error:0.406123\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:02,951 INFO [12]#011train-error:0.406119\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:06,036 INFO [13]#011train-error:0.405939\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:08,975 INFO [14]#011train-error:0.405905\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:11,886 INFO [15]#011train-error:0.405909\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:14,436 INFO [16]#011train-error:0.405732\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:17,436 INFO [17]#011train-error:0.405709\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:20,730 INFO [18]#011train-error:0.405688\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:23,684 INFO [19]#011train-error:0.405461\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:26,670 INFO [20]#011train-error:0.405434\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:29,581 INFO [21]#011train-error:0.405315\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:32,577 INFO [22]#011train-error:0.405288\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:35,510 INFO [23]#011train-error:0.405256\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:38,400 INFO [24]#011train-error:0.40511\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:41,246 INFO [25]#011train-error:0.405115\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:44,136 INFO [26]#011train-error:0.404931\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:47,108 INFO [27]#011train-error:0.404956\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:50,044 INFO [28]#011train-error:0.404867\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:52,980 INFO [29]#011train-error:0.404838\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:55,891 INFO [30]#011train-error:0.404832\u001b[0m\n",
      "\u001b[34m2022-04-19 05:53:58,699 INFO [31]#011train-error:0.40475\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:01,622 INFO [32]#011train-error:0.404724\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:04,591 INFO [33]#011train-error:0.404686\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:07,521 INFO [34]#011train-error:0.404657\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:10,392 INFO [35]#011train-error:0.404663\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:13,297 INFO [36]#011train-error:0.404634\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:16,172 INFO [37]#011train-error:0.404582\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:19,050 INFO [38]#011train-error:0.404592\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,383 INFO [39]#011train-error:0.404469\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,423 INFO Finished training\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,426 INFO Finished training\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,430 INFO Finished training\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,437 INFO Finished training\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,442 INFO Finished training\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,444 INFO @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m2022-04-19 05:54:22,444 INFO @tracker 124.32961750030518 secs between node start and job finish\u001b[0m\n",
      "\u001b[35m[2022-04-19:05:55:26:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\u001b[33m[2022-04-19:05:55:26:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\u001b[32m[2022-04-19:05:55:26:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\u001b[36m[2022-04-19:05:55:26:INFO] Master host is not alive. Training might have finished. Shutting down.... Check the logs for algo-1 machine.\u001b[0m\n",
      "\n",
      "2022-04-19 05:55:39 Uploading - Uploading generated training model\n",
      "2022-04-19 05:55:39 Completed - Training job completed\n",
      "ProfilerReport-1650347308: NoIssuesFound\n",
      "Training seconds: 1595\n",
      "Billable seconds: 1595\n",
      "CPU times: user 994 ms, sys: 109 ms, total: 1.1 s\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!CPU times: user 105 ms, sys: 9.11 ms, total: 114 ms\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=3, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "xgb_predictor.serializer = CSVSerializer()\n",
    "\n",
    "def get_prediction_row (features):\n",
    "    values = xgb_predictor.predict(features).decode('utf-8')\n",
    "    output = [f'{float(value):0.3g}' for value in values.split(',')]\n",
    "    return pd.DataFrame(output, columns = ['Pred'])\n",
    "\n",
    "\n",
    "def get_prediction_per_all(df):\n",
    "    step = 10000\n",
    "    prediction_set = pd.DataFrame()\n",
    "    for i in range(0,len(df),step):\n",
    "        feature_cols = [col for col in df.columns if 'Feature_' in col]\n",
    "        feature_sets = df.loc[i:i + (step *1)-1, feature_cols]\n",
    "        input_values = feature_sets.values.tolist()\n",
    "        output_predictions = get_prediction_row(input_values)\n",
    "        prediction_set = pd.concat([prediction_set, output_predictions],ignore_index=True)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(i)\n",
    "    return prediction_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3130000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://ads508team7/jump_start/pred_valid/data.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = wr.s3.read_csv(f's3://ads508team7/AfterFeatureEngr/test/data.csv')\n",
    "df_validation = wr.s3.read_csv(f's3://ads508team7/AfterFeatureEngr/validate/data.csv')\n",
    "\n",
    "prediction_set_test = get_prediction_per_all(df_test)  \n",
    "df_pred_test = df_test.join(prediction_set_test)\n",
    "wr.s3.to_csv(df_pred_test, 's3://ads508team7/jump_start/pred_test/data.csv', index = False)\n",
    "\n",
    "prediction_set_valid = get_prediction_per_all(df_validation)   \n",
    "df_pred_valid = df_test.join(prediction_set_valid)\n",
    "wr.s3.to_csv(df_pred_valid, 's3://ads508team7/jump_start/pred_valid/data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
